{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6899d85",
   "metadata": {},
   "source": [
    "## Weight Purning\n",
    "\n",
    "\"Magnitude-based weight pruning **gradually zeroes out model weights during the training process to achieve model sparsity.**Sparse models are easier to compress, and we can skip the zeroes during inference for latency improvements.\"<br>\n",
    "[Link to Official Page](https://www.tensorflow.org/model_optimization/guide/pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec7b50",
   "metadata": {},
   "source": [
    "#### <font color='red'> Can't Use TF Hub models because models are wrapped into KerasLayer Object which is not incompatible for optimization API at this moment</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee7ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93debb5",
   "metadata": {},
   "source": [
    "### Cats and Dogs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3baf1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224)) / 255.0\n",
    "    return  image, label\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "num_examples = metadata.splits['train'].num_examples\n",
    "num_classes = metadata.features['label'].num_classes\n",
    "\n",
    "train_batches = (raw_train.shuffle(num_examples // 4)\n",
    "                 .map(format_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "validation_batches = (raw_validation\n",
    "                      .map(format_image)\n",
    "                      .batch(BATCH_SIZE)\n",
    "                      .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "test_batches = raw_test.map(format_image).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c124a",
   "metadata": {},
   "source": [
    "### Model: Keras Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff302c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f2646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "582/582 [==============================] - 131s 213ms/step - loss: 0.4868 - accuracy: 0.9204 - val_loss: 0.7250 - val_accuracy: 0.4845\n",
      "Epoch 2/6\n",
      "582/582 [==============================] - 124s 212ms/step - loss: 0.1188 - accuracy: 0.9528 - val_loss: 0.3261 - val_accuracy: 0.8508\n",
      "Epoch 3/6\n",
      "582/582 [==============================] - 124s 212ms/step - loss: 0.1084 - accuracy: 0.9582 - val_loss: 0.1666 - val_accuracy: 0.9261\n",
      "Epoch 4/6\n",
      "582/582 [==============================] - 123s 211ms/step - loss: 0.0966 - accuracy: 0.9637 - val_loss: 0.1556 - val_accuracy: 0.9424\n",
      "Epoch 5/6\n",
      "582/582 [==============================] - 124s 212ms/step - loss: 0.0918 - accuracy: 0.9657 - val_loss: 0.4711 - val_accuracy: 0.8551\n",
      "Epoch 6/6\n",
      "582/582 [==============================] - 124s 212ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.3011 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(input_shape=(224,224,3),\n",
    "                      include_top=False,\n",
    "                      weights='imagenet',pooling='max')\n",
    "\n",
    "# Customize the output layers\n",
    "flatten_all = tf.keras.layers.Flatten()(base_model.output)\n",
    "Dense_1 = tf.keras.layers.Dense(units=512,activation='relu')(flatten_all)\n",
    "prediction_layer = tf.keras.layers.Dense(units=2, activation='softmax')(Dense_1)\n",
    "\n",
    "# Concatenate the model\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=prediction_layer)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 6\n",
    "hist = model.fit(train_batches,\n",
    "                 epochs=EPOCHS,\n",
    "                 validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1937b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 4s 61ms/step - loss: 0.3047 - accuracy: 0.8934 0s - loss: 0.3041 - accuracy\n"
     ]
    }
   ],
   "source": [
    "baseline_model_accuracy = model.evaluate(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dcaf847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_dir/ResNet/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_dir/ResNet/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model,'model_dir/ResNet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4172af2",
   "metadata": {},
   "source": [
    "#### Pruning the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4ccc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4da972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 23262\n",
      "End Steps: 1454\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "\n",
    "num_images = num_examples\n",
    "end_step = np.ceil(num_images / BATCH_SIZE).astype(np.int32) * EPOCHS\n",
    "\n",
    "print(\"Number of Images:\",num_images)\n",
    "print(\"End Steps:\", end_step)\n",
    "\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de83da0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\keras\\layers\\wrappers.py:64: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  config = {'layer': generic_utils.serialize_keras_object(self.layer)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  6/582 [..............................] - ETA: 2:16 - loss: 0.1062 - accuracy: 0.9531WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1363s vs `on_train_batch_end` time: 0.1903s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1363s vs `on_train_batch_end` time: 0.1903s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 167s 248ms/step - loss: 0.1008 - accuracy: 0.9610 - val_loss: 0.1152 - val_accuracy: 0.9514\n",
      "Epoch 2/2\n",
      "582/582 [==============================] - 145s 248ms/step - loss: 0.0618 - accuracy: 0.9759 - val_loss: 0.1181 - val_accuracy: 0.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d36c21b700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='log_dir_purning/'),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_batches,\n",
    "                      epochs=EPOCHS, \n",
    "                      validation_data=validation_batches,\n",
    "                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d575641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 5s 63ms/step - loss: 0.1086 - accuracy: 0.9536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10859815776348114, 0.9535683393478394]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_pruning.evaluate(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60e0a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_dir/Pruning/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_dir/Pruning/assets\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "tf.saved_model.save(model_for_export,'model_dir/Pruning/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f5b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
